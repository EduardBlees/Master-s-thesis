Аннотация
Предложено решение проблемы интерфейса обработки и исследования открытых данных в реальном времени с
точки зрения выделения информации о местоположении в платформе, использующей данные о местоположении
(LBS-платформе), путем создания дополнения к платформе, реализующего импорт и сопоставление открытых
данных из нескольких источников для дальнейшего выделения дополнительного признака в элементах данных и
обработки с использованием статистических показателей и кластеризации. В качестве апробации был разработан
плагин определения популярности открытых точек доступа Wi-Fi с помощью данных социальной сети ВКонтакте
для LBS-платформ Geo2Tag, реализующий предложенный метод решения проблемы производительности обработки
открытых данных в LBS-платформах. Данный плагин осуществляет импорт и сопоставление набора открытых
данных Правительства Санкт-Петербурга и архива записей в определенных районах города с выделением
дополнительного признака при помощи вычисления медианы, среднего арифметического или центров кластеров по
методу кластеризации k-means для количества записей. Для определения скорости работы плагина была проведена
серия экспериментов по измерению его производительности. Экспериментальное исследование показало, что общее
время работы плагина в первую очередь определяется скоростью загрузки открытых данных из источника, поскольку
время обработки на порядок меньше времени загрузки. Результаты показывают, что плагин может осуществлять
анализ открытых данных из удаленного источника практически в реальном времени. Разработанный метод может
быть применен не только в LBS-платформе Geo2Tag, но и для широкого класса подобных систем, так как его
реализация полагается только на наличие подсистемы импорта открытых данных, которая, в свою очередь, может
быть реализована в любой LBS-платформе. Метод также создает конкурентное преимущество для LBS-платформы,
так как позволяет расширить качественный состав данных за счет результатов анализа импортированных открытых
данных, причем способы и методики анализа, а также конечная форма представления результатов могут
определяться не только администраторами LBS-платформы, но и ее пользователями-разработчиками, поскольку
реализация метода опирается на подсистему пользовательских дополнений Введение
Проблема интерфейса обработки и исследования открытых данных с точки зрения выделения ин-
формации о местоположении актуальна в связи с быстрым ростом объема открытых данных [1] и актив-
ным внедрением технологий контекстных вычислений [2]. Согласно прогнозу на 2019 год, этот фактор
приведет к серьезному росту рынка Location Based Services (LBS) за счет интеграции технологии контек-
стной разметки с существующими технологиями LBS-платформ [3]. Существующие на текущий момент
инструменты исследования не могут решить данную проблему, поскольку они предлагают либо доста-
точно низкий уровень взаимодействия с данными (базы геоданных [4]), либо в общем случае не учиты-
вают специфики геоданных и процедуры геоконтекстной разметки (BigData-решения [5]). Однако для BS-
платформ в силу их предметной области нет подобных ограничений, благодаря чему в предыдущей рабо-
те [6] был продемонстрирован принципиальный метод решения данной проблемы путем организации
подсистемы импорта открытых данных с пользовательскими расширениями для конкретных источников.
В работе будет показано применение данного подхода с точки зрения обработки открытых данных LBS-
платформой Geo2Tag в реальном времени. Под термином «в реальном времени» подразумевается такая
скорость обработки, при которой время обработки сопоставимо или меньше, чем время передачи данных
по сети между источником и LBS-платформой.
Обзор подходов к решению задачи
Для построения решения по обработке открытых данных в реальном времени с учетом геоконтек-
стной разметки необходимо изучить существующие инструменты. Тремя наиболее типичными способами
решения поставленной задачи являются инструменты обработки Big Data, геоинформационные системы
(ГИС) и LBS-платформы.
На сегодняшний день наиболее популярной методологией обработки больших объемов данных яв-
ляется Big Data, поэтому целесообразно начать обзор принципиальных инструментов геоконтекстной
разметки именно с нее. Big Data рассматривает наборы данных, которые не могут быть обработаны тра-
диционными средствами работы с данными ввиду сложности самих данных (слабая структурированность
данных [7]), высокой скорости генерации и объема, многократно превышающего объем памяти обраба-
тывающего устройства1. Big Data решениями называют программные инструменты обработки данных,
позволяющие вести их высокопроизводительную обработку и хранение. Примерами решений, позво-
ляющими работать с Big Data, являются такие программы, как Hadoop2, Spark3, Cassandra4, Oracle Big
Data [8].
Говоря об обработке открытых данных, содержащих геоданные, необходимо также рассмотреть
ГИС. ГИС – информационная система, обеспечивающая сбор, хранение, обработку, доступ, отображение и распространение пространственно-координированных данных (пространственных данных)1. Понятие
геоинформационной системы также используется в более узком смысле – как программного продукта,
позволяющего пользователям искать, анализировать и редактировать как цифровую карту местности, так
и дополнительную информацию об объектах [9]. Примерами таких систем являются различные геобазы
данных, такие как ArcGIS2. К ним же можно отнести инструменты GIS as a service3 – Google Maps4,
OpenStreetMap5, CartoDB6, MapBox7.
Другим механизмом обработки больших объемов данных являются LBS-платформы, представ-
ляющие собой информационные системы (ИС), решающие такие же задачи, как и ГИС, но при этом ос-
новными пользователями являются разработчики прикладных программ и пользователи LBS [10]. Благо-
даря этому LBS-платформы позволяют проводить достаточно сложную обработку данных, используя ин-
терфейсы достаточно высокого уровня. Наиболее популярными LBS-платформами, согласно данным по-
исковой системы Google8, являются Geo2Tag9, Anagog10, Azoft LBS-platform11, TomTom12.
Сравнивая основные подходы к обработке больших объемов геоконтекстных данных, можно сде-
лать вывод о том, что предпочтительной технологией являются LBS-платформы, так как они сочетают в
себе возможность сложного анализа данных и предоставление интерфейсов высокого уровня. Инстру-
менты для работы с BigData имеют общеее назначение и не учитывают специфику геоконтекстных дан-
ных [11]. Недостатком ГИС является то, что предоставляемые ими интерфейсы в основном предназначе-
ны для программистов, а интерфейсы более высокого уровня, как правило, предоставляют функции ви-
зуализации данных5.
Обзор существующих решений задачи импорта и обработки открытых данных в LBS-платформах
Для определения принципиальной архитектуры предлагаемого интерфейса обработки и исследо-
вания открытых данных необходимо исследовать существующие интерфейсы работы с открытыми дан-
ными в LBS-платформах. Ограничим сравнение наиболее популярными LBS-платформами, перечислен-
ными в предыдущем разделе:
 LBS-платформа Geo2Tag является наиболее популярной LBS-платформой с открытым исходным ко-
дом13. Данное решение представляет собой набор базовых интерфейсов для построения приложений,
использующих данные о местоположении, включая хранение, обработку и визуализацию данных. Бо-
лее подробная характеристика LBS-платформы Geo2Tag дается в предыдущей работе [6].
 Сервис Anagog представляет собой высокоуровневый интерфейс к данным сенсоров, массово соби-
раемым с реальных мобильных устройств. Пользователи данной LBS-платформы взаимодействуют с
ней с помощью специального Software Development Kit (SDK), который осуществляет сбор данных и
их отправку в облачные ресурсы Anangog, где происходит обработка и геоконтекстная разметка.
 Azoft LBS-platform – закрытая платформа, собирающая данные с мобильных устройств и предостав-
ляющая готовые решения для клиентских сценариев использования.
 LBS-платформа TomTom представляет собой облачную программную платформу, позволяющую раз-
работчикам использовать готовые решения в области навигации, построения маршрутов, отображения
карт и получения актуальной информации о пробках. Для разработчиков предоставляется SDK.
Сравнение LBS-платформ будет проводиться с помощью критериев, определяющих удобство и
эффективность обработки открытых данных в рамках LBS-платформы. Для настоящей работы были вы-
браны следующие критерии.
1. Возможность сохранения данных для анализа. Этот критерий подразумевает наличие интерфейсов
для плагинов, позволяющих не только получать данные, но и сохранять их в LBS-платформу. Необхо-
димо также отметить, что в более широком понимании практически каждая LBS-платформа имеет та-
кие интерфейсы для своих пользователей, поэтому в данном критерии рассматриваются именно поль-
зовательские дополнения. Соблюдение этого критерия обеспечивает дополнительное удобство реше-
ния задач обработки открытых данных.
2. Возможность создавать пользовательские дополнения (плагины) к платформе. Системы, реализующие
данное требование, позволяют решать поставленную задачу наиболее простым и безопасным спосо-
бом – с помощью программ, создаваемых пользователями и работающих в изолированной среде.
3. Открытость платформы, под которой подразумевается доступ к исходному коду. С точки зрения зада-
чи импорта открытых данных в LBS-платформе это требование является одним из важнейших, так как
при отсутствии механизмов подключения плагинов единственным способом расширить функцио-
нальность LBS-платформы остается модификация ее исходного кода. Кроме того, даже при наличии
подсистемы плагинов в ряде случаев доступ к исходному коду может ускорить процедуру импорта от-
крытых данных за счет использования недокументированных возможностей системы и оптимизации
ее поведения для конкретного сценария.
4. Возможность импорта и обработки данных в реальном времени, что подразумевает под собой любые
интерфейсы прикладного программирования для решения указанных задач, причем эти интерфейсы
могут быть и не связаны между собой. Выполнение этого требования является одним из базовых кри-
териев решения задачи обработки открытых данных в LBS-платформе, так как при его невыполнении
реализация механизмов импорта и анализа ложится на сторонних разработчиков, которые, в свою
очередь, могут ее решить неоптимальным образом.
Для сравнения существующих решений построим таблицу оценок по критериям.
Возможность
сохранения данных
для анализа
Возможность
создавать плагины
к платформе
Открытость
платформы
Возможность импорта
и обработки данных
в реальном времени
Anagog Нет Нет Нет Есть
TomTom Нет Нет Нет Есть
AzoftLBS Нет Нет Нет Нет
Geo2Tag Есть Есть Есть Есть
Таблица. Сравнение LBS-платформ
Как видно из сравнения, основной задачей LBS-платформы является выдача и обработка данных в
реальном времени, что связывает их с Big Data решениями. Совокупности критериев наиболее полно
удовлетворяет LBS-платформа Geo2Tag, так как она обладает интерфейсами создания плагинов, а также
предоставляет возможность сохранения данных для последующей обработки.
Постановка задачи
Проведенный в предыдущем разделе обзор показал, что существующие методы работы с откры-
тыми данными не позволяют вести их обработку эффективно в смысле использования специфичных для
геоданных методов. Наиболее близкой к обозначенной проблеме технологией являются LBS-платформы,
однако ее применение в решении требует расширения существующих платформ. По этой причине целью
данной работы поставлено создание инструмента анализа открытых данных в виде расширения LBS-
платформы Geo2Tag. Расширение должно обладать следующими свойствами:
 осуществлять импорт открытых данных из нескольких источников;
 реализовывать геоконтекстную разметку импортированных данных;
 предоставлять интерфейсы для обработки импортированных данных с помощью наиболее востребо-
ванных среди исследователей методов обработки;
 работа решения должна происходить в реальном времени, т.е. скорость обработки должна быть со-
поставимой по скорости со временем передачи открытых данных по сети.
Предлагаемый способ решения
Решением поставленной задачи является разработка плагина импорта открытых данных, реали-
зующего, помимо самого импорта, функции обработки самих данных. Данная форма решения наиболее
подходит для задачи, так как плагины импорта открытых данных являются единственным способом рас-
ширения указанной LBS-платформы, что было показано в предыдущей работе [6]. Кроме того, плагин
удовлетворяет всем требованиям к решению:
 по результатам работы [6] в LBS-платформу Geo2Tag добавлены программные интерфейсы, позво-
ляющие вести импорт и обработку данных из произвольных источников;
 подсистема плагинов позволяет проводить в фоновом режиме операции любой сложности над данны-
ми платформы1.
Недостатком выбранной формы решения являются риски с точки зрения информационной безо-
пасности, так как на текущий момент LBS-платформа Geo2Tag не предусматривает методов ограничения
потенциально опасных действий плагинов. Выбор метода решения
Для решения задачи обработки открытых данных в реальном времени необходимо определить ти-
пичные задачи, решаемые потребителями открытых данных вручную. Поскольку наиболее структуриро-
ванное описание методик работы с данными содержится в научных текстах, был проведен обзор актуаль-
ных статей, посвященных исследованию открытых данных с точки зрения содержащегося в них геокон-
текста. Для изучения отбирались научные статьи за 2016 год, чья тематика сильнее всего пересекается с
поставленной проблемой. В результате были отобраны две статьи – [12] и [13].
В статье [12] было проведено исследование, основанное на обработке нескольких наборов данных,
полученных из социальной сети Instagram. Предметом исследования статьи являлся анализ регулярных
перемещений жителей Амстердама и Копенгагена с точки зрения выявления закономерностей. В иссле-
довании использовались различные методы анализа данных – анализ связности, анализ сетей, классифи-
кация, кластеризация. При этом данные анализируются как с помощью отдельных их атрибутов, так и с
помощью дополнительно вычисляемых признаков.
В статье [13] дается подробное описание технологий анализа больших геопространственных набо-
ров данных в контексте исследования концепции Smart City. В качестве материала для исследования ис-
пользуются наборы открытых данных, содержащие информацию о перемещениях людей в городах. Ме-
тодом обработки выступает вычисление статистических квантилей и моментов – медиан и математиче-
ских ожиданий для выборок.
На основании анализа статей можно сделать выводы о том, что общими характеристиками обоих
исследований являются:
1. сопоставление нескольких наборов данных;
2. вычисление дополнительных признаков для элементов наборов открытых данных, в том числе и для
отдельных подмножеств выборки.
Эти характеристики определяют функциональное наполнение разрабатываемого решения. Для оп-
ределенности будем считать, что в качестве дополнительных признаков плагин будет вычислять число-
вые статистические характеристики выборки, а также производить кластеризацию элементов. Реализация
методов теории графов (анализ связности и анализ сетей) выходит за рамки задач, решаемых LBS-
платформой Geo2Tag, и в силу отсутствия необходимых интерфейсов в СУБД MongoDb1 может привести
к сильному снижению производительности, что, в свою очередь, может привести к невыполнению требо-
вания обработки в реальном времени. Процедуры классификации объектов в неявном виде присутствуют
в процессе импорта открытых данных, поэтому их реализация не требуется [6].
Поскольку существующие интерфейсы для разработки плагинов импорта и обработки открытых
данных в LBS-платформе подразумевают асинхронную работу, это накладывает дополнительные ограни-
чения на принципиальную архитектуру плагина, помимо требования обработки в реальном времени. В
этих условиях он должен снизить время задержки между запуском и сохранением в платформу данных,
пригодных для пользователей. Для достижения этого эффекта предлагается разделение процедуры обра-
ботки на две асинхронные задачи:
1. импорт данных из всех необходимых наборов и приведение их к формату LBS-платформы;
2. сопоставление наборов и вычисление числовых статистических характеристик выборки, кластериза-
ция.
Такое разделение обеспечивает достижение необходимого уровня производительности, так как при
выполнении указанных задач последовательно пользователи уже в процессе выполнения задачи импорта
имеют доступ к данным.
Разработанное решение
В качестве решения поставленной задачи в рамках LBS-платформы Geo2Tag был реализован пла-
гин обработки и импорта открытых данных в базу данных (БД) платформы, сопоставляющий два набора
открытых данных и осуществляющий вычисление дополнительных признаков для элементов данных.
Архитектура плагина изображена на рис. 1.
В качестве модельной задачи, решаемой плагином, было выбрано определение популярности от-
крытых точек доступа Wi-Fi в г. Санкт-Петербурге с помощью статистики записей в социальной сети
ВКонтакте. Источником данных об открытых точках доступа Wi-Fi был выбран соответствующий набор с
портала открытых данных Санкт-Петербурга2. Указанная задача является актуальной, так как ограничен-
ный ресурс сетей расходуется различным образом из-за разного количества пользователей. Кроме того,
задача определения популярности открытых Wi-Fi подходит для демонстрации решения поставленной
ранее проблемы обработки открытых данных LBS-платформами в реальном времени, так как она подразумевает сопоставление данных двух различных наборов, и при этом используется достаточно большой
объем данных.
Данные, получаемые из источников, имеют формат JSON. Работа с этим форматом в Python ведет-
ся с помощью инструментов модуля JSON. После обработки данных и получения дополнительных сведе-
ний формируется JSON, соответствующий схеме Geo2Tag, также с помощью инструментов модуля JSON.
Рис. 1. Архитектура плагина
OpenDataApi module выполняет загрузку данных о бесплатных точках Wi-Fi по Санкт-Петербургу,
которые размещены в открытом доступе на сайте открытых данных Санкт-Петербурга1. VKApi module
выполняет загрузку данных о записях в социальной сети ВКонтакте за определенный промежуток време-
ни в указанной области, используя методы VK API. DataHandler module получает данные из двух других
модулей – OpenDataApi module и VKApi module и обрабатывает их. Интерфейсы импорта – реализован-
ные интерфейсы импорта данных в платформу Geo2Tag. Исходный код плагина опубликован в открытом
репозитории [14].
Первым этапом анализа импортированных объектов является использование координат точек
Wi-Fi из первого источника для получения данных о записях в социальной сети ВКонтакте за опреде-
ленное время. Вычисляется среднее по городу значение записей в области, и в сравнении с этим значени-
ем генерируется новый отличительный признак точки Wi-Fi – ее популярность. Формируется JSON в
формате, хранимом в Geo2Tag. Данные загружаются в базу.
Дополнительный признак будет считаться следующим образом: получив данные об открытых го-
родских точках доступа Wi-Fi по Санкт-Петербургу, система также получает данные из социальной сети
ВКонтакте о количестве записей за определенное время в радиусе действия этих точек Wi-Fi. Затем, в
зависимости от выбранного метода обработки данных, могут вычисляться:
1. среднее арифметическое количества записей на точку. В зависимости от полученного значения оцени-
вается популярность точки Wi-Fi;
2. медиана количества записей на точку. В зависимости от полученного значения оценивается популяр-
ность точки Wi-Fi;
3. кластеризация точек по количеству записей. В зависимости от выделенных кластеров оценивается
популярность точки Wi-Fi.
Исследование свойств решения
Для исследования скорости работы предлагаемого решения были проведены автоматизированные
тестовые запуски плагина с разными входными данными. Измерялось два типа зависимостей: зависи-
мость времени работы от количества точек Wi-Fi и от размера временного промежутка, в рамках которого
запрашивались данные из социальной сети ВКонтакте. Тесты проводились в следующих условиях: ноут-
бук с характеристиками, соответствующими средним в доступном ценовом сегменте (процессор Intel®
Core™ i5-3210M с частотой 2,5 Ггц, 4 ГБ оперативной памяти; операционная система Ubuntu 16.04.2 LTS
(Xenial Xerus); заявленная скорость интернет-соединения 100 Мбит/сек. Размер одного JSON-ответа на
запрос к VK API составляет от 0 до 40 КБ. Следует добавить, что использовалась реализация алгоритма
кластеризации из библиотеки Python-cluster2, количество выделяемых кластеров – 2. В качестве функции расстояния между элементами использовалась евклидова метрика, условием остановки итерационного
процесса служило стандартное ограничение на изменение положений главных точек кластеров1.
По результатам экспериментов было проведено исследование зависимостей времени работы пла-
гина от количества точек Wi-Fi для всех методов обработки (рис. 2 и рис. 3). Перед сравнением времени
работы всех методов необходимо исследовать на примере одного из них (базового) вид данной зависимо-
сти. В качестве базового метода было выбрано «среднее арифметическое» как самое простое для вычис-
лений. Исследуемая зависимость изображена на рис. 2, для нее также были построены линии тренда с
помощью метода наименьших квадратов (МНК). Необходимо отметить, что данные содержат шум, кото-
рый обусловлен в первую очередь нестабильностью сетевого соединения, что следует из идентичных
форм кривых на рис. 2. 
Как видно из рис. 2, разница между полным временем обработки данных плагином по методу
«среднее арифметическое» (0,1036497003x + 0,5379161301) и собственно временем загрузки данных по
сети (0,1032361531x + 0,0402164269) на порядок меньше обеих величин (0,0004135472x + 0,4976997032),
следовательно, большую часть времени работы плагина занимает именно загрузка данных из социальной
сети ВКонтакте. При этом наблюдается линейный рост времени загрузки данных в зависимости от коли-
чества точек.
На рис. 3 изображен график зависимости времени работы плагина от количества анализируемых
точек Wi-Fi при каждом методе обработки данных. Как видно из рис. 4, время обработки данных методом кластеризации больше, чем время обработ-
ки данных с выделением среднего арифметического или медианы набора. При наибольшем количестве
анализируемых точек, использованных в эксперименте, разница во времени обработки данных методом
кластеризации и методами «среднее арифметическое» и «медиана» достигает 15–20 раз. Это связано с
тем, что зависимость времени выделения дополнительного признака при использовании методов средне-
го арифметического и медианы от количества анализируемых точек Wi-Fi – линейная, а зависимость вре-
мени выделения дополнительного признака при использовании метода кластеризации – степенная. Отме-
тим, что выбранный алгоритм кластеризации имеет тот же самый характер зависимости скорости работы
от объема обрабатываемых данных [15].
Заключение
В ходе работы было показано, что решение по импорту и обработке открытых данных в реальном
времени с активной обработкой геоинформации возможно только в рамках реализации дополнения к
LBS-платформе.
Для апробации выводов был создан плагин обработки и импорта открытых данных в LBS плат-
форму Geo2Tag. Плагин загружает и сопоставляет данные о местоположении открытых Wi-Fi сетей
Санкт-Петербурга с соответствующими по географическому местоположению данными о записях в соци-
альной сети ВКонтакте для определения популярности отдельных сетей. Обработка данных после сопос-
тавления производится с помощь вычисления численных статистических характеристик (медианы и
среднего арифметического) и кластеризации по методу k-means.
Скорость обработки данных плагином была изучена экспериментально. По результатам исследо-
вания можно сделать вывод, что время осуществления процедур анализа данных самим плагином на по-
рядок меньше, чем время загрузки данных из источника. Следовательно, предложенный подход позволяет
организовать обработку открытых данных для LBS-платформ в реальном времени.
Разработанный метод был интегрирован в LBS-платформу Geo2Tag, и его внедрение показало, что
метод позволяет расширить качественный состав данных, предоставляемых LBS-платформой, результа-
тами анализа открытых данных. Кроме того, специфика метода позволяет реализовывать методы анализа
и форматы представления его результатов силами пользователей-разработчиков LBS-платформы, что соз-
дает ей дополнительное конкурентное преимущество.
В дальнейших работах планируется расширить функции обработки данных за счет более сложных
алгоритмов исследования данных, подключить новые форматы источников и более детально исследовать
расход ресурсов LBS-платформы в процессе работы плагина.